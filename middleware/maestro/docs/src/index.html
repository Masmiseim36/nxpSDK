<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Maestro Audio Framework: Getting started with Maestro framework</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="fs_logo.gif"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Maestro Audio Framework
   &#160;<span id="projectnumber">v 1.7</span>
   </div>
   <div id="projectbrief">NXP Semiconductors</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Getting started with Maestro framework </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md__home_nxf33034_repos_mcu_sdk_2_0_middleware_maestro_README"></a> </p>
<h1><a class="anchor" id="autotoc_md1"></a>
Introduction</h1>
<p>This document describes the basic usage of the Maestro Audio Framework. This framework intends to enable the chaining of basic audio processing blocks (called "elements"). These blocks then form stream processing objects ("pipeline"). This pipeline can be used for multiple audio processing use cases. The processing blocks can include (but are not limited to) different audio sources (for example file or microphone), decoders or encoders, filters or effects, and audio sinks. For detailed description of the Maestro framework, please refer to the <a class="el" href="md_ProgrammersGuide.html">programmer's guide</a>.</p>
<p>Framework overview is depicted in the following picture:</p>
<p><img src="maestroApp.svg" alt="" style="pointer-events: none;" class="inline" title="maestro overview"/></p>
<h1><a class="anchor" id="autotoc_md2"></a>
Supported examples</h1>
<ul>
<li>maestro_playback</li>
<li>maestro_record</li>
<li>maestro_usb_mic</li>
<li>maestro_usb_speaker</li>
<li>maestro_sync</li>
</ul>
<p>The examples can be found in the audio_examples folder of the desired board. The demo applications are based on FreeRTOS and use multiple tasks to form the application functionality.</p>
<h2><a class="anchor" id="autotoc_md3"></a>
maestro_playback</h2>
<ul>
<li><b>file</b>: Perform audio file decode and playback to the line-out (speaker).<ul>
<li><em>start</em>: Play default (first found) or specified audio track file.</li>
<li><em>stop</em>: Stops actual playback.</li>
<li><em>pause</em>: Pause actual track or resume if already paused.</li>
<li><em>volume</em>: Set volume. The volume can be set from 0 to 100.</li>
<li><em>seek</em>: Seek currently paused track. Seek time is absolute time in milliseconds.</li>
<li><em>track filename</em>: Select audio track to play.</li>
<li><em>list</em>: List audio files available on mounted SD card.</li>
<li><em>info</em>: Prints playback info.</li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md4"></a>
maestro_record</h2>
<ul>
<li><b>record_mic</b>: Records MIC audio and either:<ul>
<li><em>audio</em>: Playback on a codec (line-out/speaker).</li>
<li><em>file [file_name]</em>: Store samples from onboard microphone to a file on sd card.</li>
<li><em>vit</em>: On supported boards perform VoiceSeeker pre-processing, then perform voice recognition (VIT).</li>
</ul>
</li>
<li><b>opus_encode</b>: Perform opus encoding on a sample pcm file and compare with a reference.</li>
</ul>
<h2><a class="anchor" id="autotoc_md5"></a>
maestro_usb_mic</h2>
<ul>
<li><b>usb_mic</b>: Record MIC audio and playback to the USB port as an audio 2.0 microphone device.</li>
</ul>
<h2><a class="anchor" id="autotoc_md6"></a>
maestro_usb_speaker</h2>
<ul>
<li><b>usb_speaker</b>: Play data from the USB port as an audio 2.0 speaker device.</li>
</ul>
<h2><a class="anchor" id="autotoc_md7"></a>
maestro_sync</h2>
<ul>
<li><b>start</b>: Demonstrates the use of synchronous pipelines (Tx and Rx in this case).</li>
<li><b>stop</b>: Stops a running streamer.</li>
<li><b>debug [on|off]</b>: Starts / stops debugging.</li>
</ul>
<h1><a class="anchor" id="autotoc_md8"></a>
Example applications overview</h1>
<p>To set up the audio framework properly, it is necessary to create a streamer with <code>streamer_create</code> API. It is also essential to set up the desired hardware peripherals using the functions described in <code>streamer_pcm.h</code>. The Maestro example projects consist of several files regarding the audio framework. The initial file is <code>main.c</code> with code to create multiple tasks. For features including SD card (in the maestro_playback examples, reading a file from SD card is supported and in maestro_record writing to SD card is currently supported) the <code>APP_SDCARD_Task</code> is created. The command prompt and connected functionalities are handled by <code>APP_Shell_Task</code>.</p>
<p>One of the most important parts of the configuration is the <code>streamer_pcm.c</code> where the initialization of the hardware peripherals, input and output buffer management can be found. For further information please see also <code>streamer_pcm.h</code></p>
<p>In the Maestro USB examples (maestro_usb_mic and maestro_usb_speaker), the USB configuration is located in the <code>usb_device_descriptor.c</code>, <code>audio_microphone.c</code> and <code>audio_speaker.c</code> files. For further information please see also <code>usb_device_descriptor.h</code>, <code>audio_microphone.h</code> and <code>audio_speaker.h</code>.</p>
<p>In order to be able to get the messages from the audio framework, it is necessary to create a thread for receiving the messages from the streamer, which is usually called a <code>Message Task</code>. The message thread is placed in the <code>app_streamer.c</code> file, reads the streamer message queue, and reacts to the following messages:</p>
<ul>
<li>STREAM_MSG_ERROR - stops the streamer and exits the message thread</li>
<li>STREAM_MSG_EOS - stops the streamer and exits the message thread</li>
<li>STREAM_MSG_UPDATE_DURATION - prints info about the stream duration</li>
<li>STREAM_MSG_UPDATE_POSITION - prints info about current stream position</li>
<li>STREAM_MSG_CLOSE_TASK - exits the message thread</li>
</ul>
<h1><a class="anchor" id="autotoc_md9"></a>
Commands</h1>
<h2><a class="anchor" id="autotoc_md10"></a>
version</h2>
<p>Prints component versions</p>
<h2><a class="anchor" id="autotoc_md11"></a>
file</h2>
<p><code>File</code> command is supported in the maestro_playback example. The command calls the <code>STREAMER_file_Create</code> or <code>STREAMER_PCM_Create</code> function from the <code>app_streamer.c</code> file depending on whether or not <code>MULTICHANNEL_EXAMPLE</code> is defined.</p>
<ul>
<li>When <code>MULTICHANNEL_EXAMPLE</code> is not defined:<ul>
<li>The command calls <code>STREAMER_file_Create</code> function that creates the <code>STREAM_PIPELINE_FILESYSTEM</code> pipeline.</li>
<li>When <code>SSRC_PROC</code> is defined, the synchronous sample rate converter is added before the audio sink element. &#160; Playback itself can be started with <code>STREAMER_Start</code> function. The pipeline can consist of the following elements:<ul>
<li>TYPE_ELEMENT_FILE_SRC</li>
<li>TYPE_ELEMENT_DECODER</li>
<li>TYPE_ELEMENT_AUDIO_PROC (If <code>SSRC_PROC</code> is defined)</li>
<li>TYPE_ELEMENT_AUDIO_SINK &#160;</li>
</ul>
</li>
</ul>
</li>
<li>When <code>MULTICHANNEL_EXAMPLE</code> is defined:<ul>
<li>The command calls <code>STREAMER_PCM_Create</code> function, which creates <code>STREAM_PIPELINE_PCM_AUDIO</code> pipeline.</li>
<li>If the input file is an 8 channel PCM file, output to all 8 channels is available.<ul>
<li>The properties of the PCM file are set in the <code>app_streamer.c</code> file using file source properties sent to the streamer: <code>PROP_FILESRC_SET_SAMPLE_RATE</code> - default value is 96000 [Hz] <code>PROP_FILESRC_SET_NUM_CHANNELS</code> - default value is 8 <code>PROP_FILESRC_SET_BIT_WIDTH</code> - default value is 32</li>
</ul>
</li>
<li>The synchronous sample rate converter is not supported in the multi-channel examples. &#160; Playback itself can be started with <code>STREAMER_Start</code> function. The pipeline can consist of the following elements:<ul>
<li>TYPE_ELEMENT_FILE_SRC (PCM format only)</li>
<li>TYPE_ELEMENT_AUDIO_SINK</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Other possible element types could be found in the <code><a class="el" href="streamer__api_8h.html" title="Streamer API header. Public APIs for using the maestro streamer framework.">streamer_api.h</a></code>.</p>
<p>Each of the elements has several properties that can be accessed using <code>streamer_get_property</code>. These properties allow a user to change the values of the appropriate elements. The list of properties can be found in <code><a class="el" href="streamer__element__properties_8h.html" title="Header for streamer element properties.">streamer_element_properties.h</a></code>. See the example of setting property value in the following piece of code from <code>app_streamer.c</code>:</p>
<div class="fragment"><div class="line"><a class="code" href="structELEMENT__PROPERTY__T.html">ELEMENT_PROPERTY_T</a> prop;</div>
<div class="line"> </div>
<div class="line"><a class="code" href="structEXT__PROCESS__DESC__T.html">EXT_PROCESS_DESC_T</a> ssrc_proc = {SSRC_Proc_Init, SSRC_Proc_Execute, SSRC_Proc_Deinit, &amp;get_app_data()-&gt;proc_args};</div>
<div class="line"> </div>
<div class="line">prop.<a class="code" href="structELEMENT__PROPERTY__T.html#a40dc39f13a8d25b45d19d63498082e10">prop</a> = PROP_SRC_PROC_FUNCPTR;</div>
<div class="line">prop.<a class="code" href="structELEMENT__PROPERTY__T.html#ab1013a8983adf70b4cffba4637ad1df8">val</a>  = (uintptr_t)&amp;ssrc_proc;</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> (<a class="code" href="streamer__api_8h.html#af0f2ba1e35082e033d66b106438b51e8">streamer_set_property</a>(streamer, 0, prop, <span class="keyword">true</span>) != 0)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">return</span> -1;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">prop.<a class="code" href="structELEMENT__PROPERTY__T.html#a40dc39f13a8d25b45d19d63498082e10">prop</a> = PROP_AUDIOSINK_SET_VOLUME;</div>
<div class="line">prop.<a class="code" href="structELEMENT__PROPERTY__T.html#ab1013a8983adf70b4cffba4637ad1df8">val</a>  = volume;</div>
<div class="line"><a class="code" href="streamer__api_8h.html#af0f2ba1e35082e033d66b106438b51e8">streamer_set_property</a>(streamer, 0, prop, <span class="keyword">true</span>);</div>
<div class="ttc" id="astreamer__api_8h_html_af0f2ba1e35082e033d66b106438b51e8"><div class="ttname"><a href="streamer__api_8h.html#af0f2ba1e35082e033d66b106438b51e8">streamer_set_property</a></div><div class="ttdeci">int32_t streamer_set_property(STREAMER_T *streamer, int8_t pipeline_id, ELEMENT_PROPERTY_T prop, bool block)</div><div class="ttdoc">Set element property.</div><div class="ttdef"><b>Definition:</b> streamer.c:784</div></div>
<div class="ttc" id="astructELEMENT__PROPERTY__T_html"><div class="ttname"><a href="structELEMENT__PROPERTY__T.html">ELEMENT_PROPERTY_T</a></div><div class="ttdoc">Element Property structure.</div><div class="ttdef"><b>Definition:</b> streamer_api.h:567</div></div>
<div class="ttc" id="astructELEMENT__PROPERTY__T_html_a40dc39f13a8d25b45d19d63498082e10"><div class="ttname"><a href="structELEMENT__PROPERTY__T.html#a40dc39f13a8d25b45d19d63498082e10">ELEMENT_PROPERTY_T::prop</a></div><div class="ttdeci">uint16_t prop</div><div class="ttdoc">property type</div><div class="ttdef"><b>Definition:</b> streamer_api.h:568</div></div>
<div class="ttc" id="astructELEMENT__PROPERTY__T_html_ab1013a8983adf70b4cffba4637ad1df8"><div class="ttname"><a href="structELEMENT__PROPERTY__T.html#ab1013a8983adf70b4cffba4637ad1df8">ELEMENT_PROPERTY_T::val</a></div><div class="ttdeci">uintptr_t val</div><div class="ttdoc">property value</div><div class="ttdef"><b>Definition:</b> streamer_api.h:569</div></div>
<div class="ttc" id="astructEXT__PROCESS__DESC__T_html"><div class="ttname"><a href="structEXT__PROCESS__DESC__T.html">EXT_PROCESS_DESC_T</a></div><div class="ttdoc">External processing funcion prototypes and arguments.</div><div class="ttdef"><b>Definition:</b> streamer_element_properties.h:23</div></div>
</div><!-- fragment --><p>Some of the predefined values can be found in the <code><a class="el" href="streamer__api_8h.html" title="Streamer API header. Public APIs for using the maestro streamer framework.">streamer_api.h</a></code>.</p>
<h2><a class="anchor" id="autotoc_md12"></a>
record_mic</h2>
<p><code>Record_mic</code> command is only supported in the maestro_record example. The command creates pipeline described in the <code>STREAMER_mic_Create</code> function in the <code>app_streamer.c</code> file. The pipeline is selected with <code>STREAM_PIPELINE_PCM</code>, <code>STREAM_PIPELINE_MIC2FILE</code> or <code>STREAM_PIPELINE_VIT</code> in <code>pipeline_type</code> parameter. Depending on the command option, that may be either <code>audio</code>, <code>file</code> or <code>vit</code>. This configuration takes samples from the microphone input and sends them to the audio sink (speaker(s) or filesystem) with optional processing in between.</p>
<p>The pipeline can consist of the following elements:</p><ul>
<li>TYPE_ELEMENT_AUDIO_SRC</li>
<li>TYPE_ELEMENT_AUDIO_PROC (If <code>VOICE_SEEKER_PROC</code> is defined and the VIT option has been selected)</li>
<li>TYPE_ELEMENT_AUDIO_SINK or TYPE_ELEMENT_FILE_SINK or TYPE_ELEMENT_VIT_SINK</li>
</ul>
<p>Other possible element types and some of the predefined values could be found in the <code><a class="el" href="streamer__api_8h.html" title="Streamer API header. Public APIs for using the maestro streamer framework.">streamer_api.h</a></code>.</p>
<h2><a class="anchor" id="autotoc_md13"></a>
opus encode</h2>
<p><code>Opus_encode</code> command is only supported in the maestro_record example. The command creates pipeline described in the <code>STREAMER_opusmem2mem_Create</code> function in the <code>app_streamer.c</code> file. The pipeline is selected with <code>STREAM_PIPELINE_OPUS_MEM2MEM</code> in <code>pipeline_type</code> parameter. This configuration takes PCM samples from memory and sends them to the Opus encoder. The encoded data is stored in memory and compared to a reference.</p>
<p>The pipeline can consist of the following elements:</p><ul>
<li>TYPE_ELEMENT_MEM_SRC</li>
<li>TYPE_ELEMENT_ENCODER</li>
<li>TYPE_ELEMENT_MEM_SINK</li>
</ul>
<p>Other possible element types and some of the predefined values could be found in the <code><a class="el" href="streamer__api_8h.html" title="Streamer API header. Public APIs for using the maestro streamer framework.">streamer_api.h</a></code>.</p>
<h2><a class="anchor" id="autotoc_md14"></a>
usb_mic</h2>
<p><code>Usb_mic</code> command is only supported in the maestro_usb_mic example. The command creates pipeline described in the <code>STREAMER_mic_Create</code> function in the <code>app_streamer.c</code> file. The pipeline is selected with <code>STREAM_PIPELINE_PCM</code> in <code>pipeline_type</code> parameter. This configuration takes samples from the microphone input and sends them to the audio sink (USB port). The pipeline can consist of the following elements:</p><ul>
<li>TYPE_ELEMENT_AUDIO_SRC</li>
<li>TYPE_ELEMENT_AUDIO_SINK</li>
</ul>
<p>Other possible element types and some of the predefined values could be found in <code><a class="el" href="streamer__api_8h.html" title="Streamer API header. Public APIs for using the maestro streamer framework.">streamer_api.h</a></code>.</p>
<h2><a class="anchor" id="autotoc_md15"></a>
usb_speaker</h2>
<p><code>Usb_speaker</code> command is only supported in the maestro_usb_speaker example. The command creates pipeline described in the <code>STREAMER_speaker_Create</code> function in the <code>app_streamer.c</code> file. The pipeline is selected with <code>STREAM_PIPELINE_PCM</code> in <code>pipeline_type</code> parameter. This configuration takes samples from the USB port and sends them to the audio sink (speaker output). The pipeline can consist of the following elements:</p><ul>
<li>TYPE_ELEMENT_AUDIO_SRC</li>
<li>TYPE_ELEMENT_AUDIO_SINK</li>
</ul>
<p>Other possible element types and some of the predefined values could be found in <code><a class="el" href="streamer__api_8h.html" title="Streamer API header. Public APIs for using the maestro streamer framework.">streamer_api.h</a></code>.</p>
<h2><a class="anchor" id="autotoc_md16"></a>
start</h2>
<p><code>Start</code> command is only supported in the maestro_sync example. The command creates two pipelines described in the <code>STREAMER_Create</code> function in the <code>app_streamer.c</code> file. The pipelines are selected with the <code>STREAM_PIPELINE_PCM_AUDIO_MEM</code> and <code>STREAM_PIPELINE_VIT_FILESINK</code> in <code>pipeline_type</code> parameter. This configuration should demonstrate the use of synchronous pipelines (Tx and Rx in this case) in a single streamer task.</p>
<ul>
<li>Playback (Tx) pipeline:<ul>
<li>Playback of audio data in PCM format stored in flash memory to the speaker.</li>
</ul>
</li>
<li>Recording (Rx) pipline:<ul>
<li>Record audio data using a microphone.</li>
<li>VoiceSeeker processing.</li>
<li>Wake words + voice commands recognition.</li>
<li>Save VoiceSeeker output to SD card. &#160;</li>
</ul>
</li>
<li>The playback (Tx) pipeline consists of the following elements:<ul>
<li>TYPE_ELEMENT_MEM_SRC</li>
<li>TYPE_ELEMENT_AUDIO_SINK</li>
</ul>
</li>
<li>The recording (Rx) pipeline consists of the following elements:<ul>
<li>TYPE_ELEMENT_AUDIO_SRC</li>
<li>TYPE_ELEMENT_AUDIO_PROC (as VoiceSeeker)</li>
<li>TYPE_ELEMENT_AUDIO_PROC (as VIT)</li>
<li>TYPE_ELEMENT_FIlE_SINK</li>
</ul>
</li>
</ul>
<p>Other possible element types and some of the predefined values could be found in <code><a class="el" href="streamer__api_8h.html" title="Streamer API header. Public APIs for using the maestro streamer framework.">streamer_api.h</a></code>.</p>
<h1><a class="anchor" id="autotoc_md17"></a>
Configuration options</h1>
<p>Users can change the pipeline type when creating the streamer object. Currently tested options are:</p><ul>
<li><code>STREAM_PIPELINE_PCM</code></li>
<li><code>STREAM_PIPELINE_NETBUF</code></li>
<li><code>STREAM_PIPELINE_FILESYSTEM</code></li>
<li><code>STREAM_PIPELINE_MIC2FILE</code></li>
<li><code>STREAM_PIPELINE_VIT</code></li>
<li><code>STREAM_PIPELINE_MEM</code></li>
<li><code>STREAM_PIPELINE_OPUS_MEM2MEM</code></li>
<li><code>STREAM_PIPELINE_PCM_AUDIO</code></li>
<li><code>STREAM_PIPELINE_PCM_AUDIO_MEM</code></li>
<li><code>STREAM_PIPELINE_VIT_FILESINK</code></li>
</ul>
<p>In order to create a user defined pipeline, please see the <a class="el" href="md_ProgrammersGuide.html">programmer's guide</a>.</p>
<h1><a class="anchor" id="autotoc_md18"></a>
Supported features</h1>
<p>The current version of the audio framework supports some optional features. These can be limited to some MCU cores or boards variants.</p>
<h2><a class="anchor" id="autotoc_md19"></a>
Codecs</h2>
<p>The maestro_playback can play multiple files with the <code>file</code> option (<code>STREAM_PIPELINE_FILESYSTEM</code>). The <code>opus</code> (as standalone or as a part of <code>ogg</code> encapsulation) and <code>mp3</code> codecs are supported for now. For detailed code handling this file extension please check <code>cmd.c</code> file and <code>shellFile()</code> function. Supported codecs and its options are:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Decoder   </th><th class="markdownTableHeadNone">Sample rates [kHz]   </th><th class="markdownTableHeadNone">Number of channels   </th><th class="markdownTableHeadNone">Bit depth    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">AAC   </td><td class="markdownTableBodyNone">8, 11.025, 16, 22.050, 24, 32, 44.1, 48   </td><td class="markdownTableBodyNone">1, 2 (mono/stereo)   </td><td class="markdownTableBodyNone">16    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">FLAC   </td><td class="markdownTableBodyNone">8, 11.025, 16, 22.050, 24, 32, 44.1, 48   </td><td class="markdownTableBodyNone">1, 2 (mono/stereo)   </td><td class="markdownTableBodyNone">16    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">MP3   </td><td class="markdownTableBodyNone">8, 11.025, 16, 22.050, 32, 44.1, 48   </td><td class="markdownTableBodyNone">1, 2 (mono/stereo)   </td><td class="markdownTableBodyNone">16    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">opus   </td><td class="markdownTableBodyNone">8, 16, 24, 48   </td><td class="markdownTableBodyNone">1, 2 (mono/stereo)   </td><td class="markdownTableBodyNone">16    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">WAV   </td><td class="markdownTableBodyNone">8, 11.025, 16, 22.050, 32, 44.1, 48   </td><td class="markdownTableBodyNone">1, 2 (mono/stereo)   </td><td class="markdownTableBodyNone">8, 16, 24   </td></tr>
</table>
<p>For more details about the codecs please see following documents: <a class="el" href="aacdec_start.html#md_aacdec">AAC decoder</a>,<a class="el" href="flacdec_start.html#md_flacdec">FLAC decoder</a>,<a class="el" href="mp3dec_start.html#md_mp3dec">MP3 decoder</a>,<a href="https://opus-codec.org/docs/opus_api-1.3.1/">opus</a>,<a class="el" href="md_wavdec.html">WAV decoder</a></p>
<p>Using maestro_playback_8ch_96kHz example users can play PCM files from the SD card and output either 2 or 8 channels with 96kHz sampling rate and 32bit depth (just RT1060-EVKB with AUD-EXP-42448 expansion board supported).</p>
<h2><a class="anchor" id="autotoc_md20"></a>
VIT</h2>
<p>VIT can be enabled for the <code>record_mic</code> command using the <code>vit</code> option. In the <code>STREAMER_mic_Create</code> function in the <code>app_streamer.c</code> file, the <code>VIT_PROC</code> preprocessor define ensures the creation of pipeline with VIT (<code>STREAM_PIPELINE_VIT</code>). More details about VIT are available in the VIT package, which is located in <code>middleware\vit\{platform}\Doc\</code>(depending on the platform) or via following <a href="https://nxp.com/vit">link</a>.</p>
<h2><a class="anchor" id="autotoc_md21"></a>
VoiceSeeker</h2>
<p>VoiceSeeker can be enabled for the <code>record_mic</code> command using the <code>vit</code> option. In the <code>STREAMER_mic_Create</code> function in the <code>app_streamer.c</code> file, the <code>VIT_PROC</code> and <code>VOICE_SEEKER_PROC</code> preprocessor defines ensure the creation of pipeline with VIT and VoiceSeeker (<code>STREAM_PIPELINE_VIT</code>). More details about VoiceSeeker are available in the VoiceSeeker package, which is located in <code>middleware\voice_seeker\{platform}\Doc\</code>(depending on the platform) or via following <a href="https://nxp.com/voiceseeker">link</a>.</p>
<h2><a class="anchor" id="autotoc_md22"></a>
SSRC</h2>
<p>Synchronous sample rate converter can be enabled for the <code>file</code> command. In the <code>STREAMER_file_Create</code> function on the <code>app_streamer.c</code> file <code>SSRC_PROC</code> preprocessor define ensures the creation of pipeline with the synchronous sample rate converter. More details about SSRC are available in the User Guide, which is located in <code>middleware\maestro\mcu-audio\ssrc\doc\</code>.</p>
<h2><a class="anchor" id="autotoc_md23"></a>
ASRC</h2>
<p>Asynchronous sample rate converter is not used in our examples, but it is part of the maestro middleware and can be enabled. To enable ASRC, the <code>maestro_framework_asrc</code> and <code>CMSIS_DSP_Library_Source</code> components must be added to the project. Furthermore, it is necessary to switch from Redlib to Newlib (semihost) library and add a platform definition to the project (e.g. for RT1170: <code>PLATFORM_RT1170_CORTEXM7</code>). Supported platforms can be found in the <code>PL_platformTypes.h</code> file. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.5-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul class="foot">
    <li class="footer">&copy; 2020 NXP Semiconductors. All rights reserved.
    </li>
  </ul>
</div>
</body>
</html>
